{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgFNGoyIAetc"
      },
      "source": [
        "# Adding KNN memory to transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RFekiB0Aete"
      },
      "source": [
        "This code demonstrates how to enhance transformer models using k-Nearest Neighbors (kNN) memory. The idea is to integrate an external memory to a transformer architecture, allowing it to look up relevant past information from previous steps, which can improve the model’s performance on tasks requiring long-term context. Let's go through the code in simpler terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3j_oJO0M3rW"
      },
      "source": [
        "One of the transformer layers near the top of the stack is a kNN-augmented attention layer, which\n",
        "combines two forms of attention. Like all of the other layers, it uses standard dense self-attention on\n",
        "the local context, which is the input subsequence for the current training step. Unlike the other layers,\n",
        "however, it also does an approximate k-nearest-neighbor search into the external memory.\n",
        "\n",
        "The same queries are used for both the local context, and for the external memory. The keys and\n",
        "values also belong to the same distribution; after each training step, the (key, value) pairs in the local\n",
        "context are appended to the end of the external memory. If the document is very long, old (key, value)\n",
        "pairs will be dropped from the memory to make room for new ones. Thus, for each head, the external\n",
        "memory keeps a cache of the prior M (key, value) pairs, where M is the memory size.\n",
        "\n",
        "The kNN lookup will return a set of retrieved memories, which consist of the top-k (key, value) pairs\n",
        "that kNN search returns for each query (i.e. each token) in the input subsequence. As with standard\n",
        "dense attention, we first construct an attention matrix by computing the dot product of each query\n",
        "against the retrieved keys, then apply softmax, and finally return a weighted sum of the retrieved\n",
        "values. Unlike standard dense attention, the retrieved memories contain a different set of (key, value)\n",
        "pairs for each query.\n",
        "\n",
        "Attention over the local context is performed in the usual way. The results of kNN-attention and local\n",
        "attention are then combined using a learned gate:\n",
        "\n",
        "gate = sigmoid(bias_parameter)\n",
        "\n",
        "combined_attention = (local_attention * gate) + (external_attention * (1-gate))\n",
        "\n",
        "Where bias_parameter is differentiable scalar, one per head. This parameter learns how to balance local and external attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb58tQf8Aetg"
      },
      "source": [
        "### Installing Libraries:\n",
        "\n",
        "- faiss: A library used for fast nearest neighbor search. It allows you to perform efficient k-nearest neighbors (kNN) search on large datasets. Here, it's being installed and imported.\n",
        "- torch: The popular PyTorch library used for building machine learning models.\n",
        "- numpy: A library used for working with arrays and numerical computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs0EM2YfM-DS",
        "outputId": "ad3a44f8-bf5f-4665-fb7c-446ecc8d9073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu\n",
        "import faiss\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIfibFv2pkWh",
        "outputId": "d88a34bf-9a52-471f-86f1-a3f0522bc788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "from einops import rearrange, repeat, pack, unpack, einsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7FZXFQNAetj"
      },
      "source": [
        "### Setting Up kNN Index\n",
        "\n",
        "- dim: Defines the dimensionality of the vectors in the kNN index (64 in this case).\n",
        "- faiss.IndexFlatL2(dim): Creates a simple index for kNN searches using the L2 distance metric (Euclidean distance). This index will be used to store and retrieve vector embeddings (e.g., token representations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JwtbM2VYA5gX"
      },
      "outputs": [],
      "source": [
        "dim = 64\n",
        "index = faiss.IndexFlatL2(dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRVkI7SXAetk"
      },
      "source": [
        "### Creating and Adding Data to kNN Index\n",
        "\n",
        "- vector_data: A random dataset with 10,000 vectors of size dim=64. These vectors will be used for the kNN search.\n",
        "- index.add(): This method adds the vectors to the kNN index for future lookups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3yCA_CcMA5hX"
      },
      "outputs": [],
      "source": [
        "vector_data = np.random.random((10000, dim)).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i8I2Ba4VA5jg"
      },
      "outputs": [],
      "source": [
        "index.add(vector_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnm6sE-PaKEm",
        "outputId": "a6cf2a0d-9754-4440-a7f0-263c94c041a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "index.ntotal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSxbd2X6aKGS",
        "outputId": "81a19936-ed6a-4c83-f442-04235a7396ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "index.remove_ids(np.arange(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XlesKFraKIo",
        "outputId": "0c68fb53-3cfe-4a26-8d5a-0e2e77b83e97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9990"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "index.ntotal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rs7GixJAetm"
      },
      "source": [
        "### Querying the kNN Index\n",
        "\n",
        "- query_data: A set of 10 random vectors to query against the kNN index.\n",
        "- top_k = 2: We want to retrieve the top 2 closest neighbors for each query.\n",
        "- index.search(): This method performs the kNN search. It returns:\n",
        "    - distance: The Euclidean distance between the query vectors and the retrieved neighbors.\n",
        "    - ids: The indices of the closest neighbors found in the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C2XouVElaQoz"
      },
      "outputs": [],
      "source": [
        "query_data = np.random.random((10, dim)).astype('float32')\n",
        "top_k = 2\n",
        "distance, ids = index.search(query_data, top_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiscRNSEaQqt",
        "outputId": "e19581e1-7fe2-4cc6-d64d-85335912b8a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.620409 , 5.8326654],\n",
              "       [5.0630836, 5.379696 ],\n",
              "       [5.636686 , 5.7546487],\n",
              "       [6.5205274, 6.8329067],\n",
              "       [5.2549725, 5.375698 ],\n",
              "       [6.1668134, 6.6554174],\n",
              "       [5.416364 , 6.0980406],\n",
              "       [5.612576 , 5.872774 ],\n",
              "       [5.0625024, 5.1286287],\n",
              "       [5.090478 , 6.277242 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuKL7XQXaQs8",
        "outputId": "84bf31e9-889c-4191-ae6b-411ea3a6f79a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7123, 2909],\n",
              "       [5498, 9134],\n",
              "       [2782, 6815],\n",
              "       [1810, 9503],\n",
              "       [4520, 1717],\n",
              "       [ 905,  715],\n",
              "       [1120, 3618],\n",
              "       [8247, 5126],\n",
              "       [4457, 5163],\n",
              "       [ 665, 2275]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The search_and_reconstruct method in Faiss is a useful function in the FAISS library that not only searches for the nearest neighbors of a query vector but also retrieves the original vectors stored in the index for those neighbors. This is particularly valuable when you need both the indices of the nearest neighbors and their corresponding vectors.\n",
        "\n",
        "- Search:\n",
        "Similar to the search method, search_and_reconstruct finds the top k nearest neighbors for each query vector based on the chosen similarity metric (e.g., L2 distance or cosine similarity).\n",
        "\n",
        "- Reconstruct:\n",
        "Once the nearest neighbors are identified, it reconstructs the original vectors (from the dataset) that correspond to these neighbors. These reconstructed vectors are often useful for applications where you need the raw data associated with the nearest neighbors rather than just their indices."
      ],
      "metadata": {
        "id": "WSNTeZLEHldi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkTTb3bkaQvO",
        "outputId": "59fba947-c73d-4ab4-d931-b5e8e88f34df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.620409 , 5.8326654],\n",
              "        [5.0630836, 5.379696 ],\n",
              "        [5.636686 , 5.7546487],\n",
              "        [6.5205274, 6.8329067],\n",
              "        [5.2549725, 5.375698 ],\n",
              "        [6.1668134, 6.6554174],\n",
              "        [5.416364 , 6.0980406],\n",
              "        [5.612576 , 5.872774 ],\n",
              "        [5.0625024, 5.1286287],\n",
              "        [5.090478 , 6.277242 ]], dtype=float32),\n",
              " array([[7123, 2909],\n",
              "        [5498, 9134],\n",
              "        [2782, 6815],\n",
              "        [1810, 9503],\n",
              "        [4520, 1717],\n",
              "        [ 905,  715],\n",
              "        [1120, 3618],\n",
              "        [8247, 5126],\n",
              "        [4457, 5163],\n",
              "        [ 665, 2275]]),\n",
              " array([[[0.8076478 , 0.67531157, 0.22166291, ..., 0.6731062 ,\n",
              "          0.6935085 , 0.03726348],\n",
              "         [0.9184147 , 0.6368605 , 0.22319569, ..., 0.76023334,\n",
              "          0.08740996, 0.8329671 ]],\n",
              " \n",
              "        [[0.4025765 , 0.51826936, 0.22416422, ..., 0.25313255,\n",
              "          0.5544181 , 0.50589734],\n",
              "         [0.21780738, 0.34675562, 0.03360439, ..., 0.17692722,\n",
              "          0.41294774, 0.7699829 ]],\n",
              " \n",
              "        [[0.00225048, 0.52846795, 0.98167723, ..., 0.18795003,\n",
              "          0.86078006, 0.730716  ],\n",
              "         [0.52797985, 0.04988107, 0.8138792 , ..., 0.52987224,\n",
              "          0.3964478 , 0.9376415 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.73472023, 0.7261556 , 0.75919455, ..., 0.01903084,\n",
              "          0.6294901 , 0.1803387 ],\n",
              "         [0.61145955, 0.44663444, 0.8453564 , ..., 0.58001024,\n",
              "          0.66037005, 0.28646427]],\n",
              " \n",
              "        [[0.30101633, 0.5732277 , 0.262209  , ..., 0.80779994,\n",
              "          0.3939075 , 0.14138626],\n",
              "         [0.721954  , 0.58565366, 0.14764588, ..., 0.17118818,\n",
              "          0.3868321 , 0.6831954 ]],\n",
              " \n",
              "        [[0.4578982 , 0.4812442 , 0.20345028, ..., 0.30787116,\n",
              "          0.39640796, 0.54934675],\n",
              "         [0.20528635, 0.20794304, 0.52574426, ..., 0.5785745 ,\n",
              "          0.9786545 , 0.42719188]]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "index.search_and_reconstruct(query_data, top_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuNJJkqCAetn"
      },
      "source": [
        "### Memory Management with np.memmap\n",
        "\n",
        "- np.memmap(): Creates a memory-mapped array, allowing you to efficiently store and access large arrays without loading everything into RAM at once. This is important for managing the \"external memory\" used by the transformer.\n",
        "- max_memories = 10000: Defines the maximum number of memory slots (10,000 key-value pairs) that can be stored in this memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XDYiPdH0aQxV"
      },
      "outputs": [],
      "source": [
        "db_filepath = \"./memory.memmap\"\n",
        "max_memories = 10000\n",
        "shape = (max_memories, 2, dim)\n",
        "db = np.memmap(db_filepath, mode = 'w+', dtype = np.float32, shape = shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtNSGUuraQzZ",
        "outputId": "1f9a8067-8ae7-41c5-bcfb-61eed8f33e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "memmap([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ0q-TQFAeto"
      },
      "source": [
        "### Adding Key-Value Pairs to Memory\n",
        "\n",
        "Adds random key-value pairs to the memory (db) in the form of 3D arrays with dimensions (batch_size, 2, dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NZCTisi1aQ1j"
      },
      "outputs": [],
      "source": [
        "db[1:2] = np.random.rand(1,2,dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUd6WbOYaQ31",
        "outputId": "b43d7ea0-0147-4c43-b463-cad6ac2992f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "memmap([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.48390037, 0.33972484, 0.4520095 , ..., 0.8959501 ,\n",
              "          0.1619047 , 0.4994492 ],\n",
              "         [0.9100345 , 0.23197599, 0.04336949, ..., 0.3611623 ,\n",
              "          0.19715595, 0.91898817]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dpLhiqRaCKtH"
      },
      "outputs": [],
      "source": [
        "db[0] = torch.randn(1,2,dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Nwq-_eCrEx",
        "outputId": "d437d62a-2f30-4c1f-f4f4-ebfb83ee9a7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.memmap"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "type(db[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtR2byyHCwyB",
        "outputId": "ff64d207-b34f-4234-c2e0-5ce570af0777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "db[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose and Use\n",
        "\n",
        "- Faiss Index:\n",
        "\n",
        "Handles nearest-neighbor searches efficiently.\n",
        "\n",
        "- Memory-Mapped Database:\n",
        "\n",
        "Stores vectors persistently while minimizing RAM usage.\n",
        "\n",
        "- Workflow:\n",
        "\n",
        "Add vectors to both the Faiss index and the memory-mapped database.\n",
        "Perform nearest-neighbor searches using the Faiss index.\n",
        "Retrieve associated metadata or additional information from the database."
      ],
      "metadata": {
        "id": "feYptO1iIu-q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1GxPfQAMe40N"
      },
      "outputs": [],
      "source": [
        "dim = 10\n",
        "max_memories = 10000\n",
        "batch_size = 16\n",
        "top_k = 3\n",
        "\n",
        "db_filepath = \"./memory.memmap\"\n",
        "shape = (max_memories, 2, dim) # each memory slot will store two vectors (e.g., key and value) of size dim.\n",
        "\n",
        "\n",
        "# create index\n",
        "index = faiss.IndexFlatL2(dim) # Flat indices store all vectors in memory and perform brute-force search, which is simple and fast for small datasets.\n",
        "\n",
        "# create database\n",
        "db = np.memmap(db_filepath, mode = 'w+', dtype = np.float32, shape = shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsqENgjUe5CF"
      },
      "outputs": [],
      "source": [
        "# KNN DATABASE CLASS\n",
        "\n",
        "# add to index\n",
        "# add to database\n",
        "# query the index\n",
        "# retrieve from the database\n",
        "# remove/clear from index and database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er4lJv9a7met"
      },
      "source": [
        "### Adding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV9OBQYoh5O8",
        "outputId": "39554070-8c00-46d2-b327-91397bf34470"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 2, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "kv = np.random.rand(batch_size, 512, 2, dim).astype('float32') # b t 2 (hd)\n",
        "kv = kv.reshape(-1, 2, dim)\n",
        "kv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKQn09-9h5Sv",
        "outputId": "f40feb28-da32-46fa-d878-67996a49e7c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "k = kv[:,0,:]\n",
        "k.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Use np.ascontiguousarray?\n",
        "- np.ascontiguousarray ensures that the array k is stored in a contiguous block of memory.\n",
        "- Faiss requires input arrays to be contiguous in memory because it uses highly optimized, low-level C++ routines for speed.\n",
        "- If k is not contiguous (e.g., due to slicing, transposing, or other operations in NumPy), this function creates a contiguous version of the array without changing its data."
      ],
      "metadata": {
        "id": "c2TJ19g-JCXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4SjJz_jyh5VO"
      },
      "outputs": [],
      "source": [
        "index.add(np.ascontiguousarray(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "__B53GMc4Txw"
      },
      "outputs": [],
      "source": [
        "db_offset = 0\n",
        "kv_len = kv.shape[0]\n",
        "ids = (np.arange(kv_len) + db_offset)\n",
        "db_offset += kv_len\n",
        "db[ids] = kv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhTf5VLN7pMk"
      },
      "source": [
        "### Query and Retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798Vk0JhITzf",
        "outputId": "754ca58e-805d-472c-a17a-be1da82b8baa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "query = np.random.rand(batch_size, 512, dim).astype('float32') # b t (hd)\n",
        "query = query.reshape(-1, dim)\n",
        "query.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFxTDz0HJI0K",
        "outputId": "262d9e7b-3751-4469-ae9b-9c7d19110097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "distance, ids = index.search(query, top_k)\n",
        "ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOrlfi2EJI2d",
        "outputId": "5eae3d3c-16f8-491f-bc3d-01b3ba89071e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2842, 7248, 3524],\n",
              "       [7323, 4428,  819],\n",
              "       [7501, 3558, 1737],\n",
              "       ...,\n",
              "       [6382, 6064, 1774],\n",
              "       [2072, 8127, 8118],\n",
              "       [ 738, 6222, 4904]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCEo7sgYJI3w",
        "outputId": "33baa350-08b1-4c6f-9f6d-ffa6df4b2049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 3, 2, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "retrieved_kvs = db[ids]\n",
        "retrieved_kvs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGuXiO_PIT10",
        "outputId": "d83bed50-fbdc-49b8-cf06-14e6482c313a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 512, 3, 2, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "retrieved_kvs = retrieved_kvs.reshape(16, 512, 3, 2, 10)\n",
        "retrieved_kvs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXjNm0dkK-d4"
      },
      "source": [
        "### Remove / Clear / Database management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRScUINTD_4a"
      },
      "outputs": [],
      "source": [
        "# 5120\n",
        "# 10 segments of 512 tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBQ6-StDmm9Y"
      },
      "source": [
        "### KNN Class\n",
        "\n",
        "- This class is designed to manage the kNN memory for the transformer.\n",
        "- It initializes with dim (dimension of each vector) and max_memories (maximum number of key-value pairs).\n",
        "- A memory-mapped file db is created to store the key-value pairs, and faiss.IndexFlatL2 is used for the kNN search index.    \n",
        "\n",
        "Adding New Data and Updating Memory\n",
        "- add() method flattens the input data, adds it to both the memory (db) and the kNN index (index).\n",
        "- Only the \"keys\" (i.e., the first part of each key-value pair) are added to the kNN index, as they are used to perform the search.\n",
        "\n",
        "Searching and Retrieving from Memory\n",
        "- search() method flattens the query vectors, performs a kNN search, and retrieves the most relevant key-value pairs from memory.\n",
        "- It reshapes the results back to their original dimensions for easy use in the transformer model.\n",
        "\n",
        "Clearing Memory and Index\n",
        "- The clear() method resets the kNN index and clears the memory, allowing for a fresh start.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nU_WGXaT700G"
      },
      "outputs": [],
      "source": [
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories,\n",
        "        ):\n",
        "        self.dim = dim\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (max_memories, 2, dim)\n",
        "        self.db_offset = 0\n",
        "        self.db_filepath = \"./memory.memmap\"\n",
        "        self.db = np.memmap(self.db_filepath, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "\n",
        "    def add_to_db(self, new_data):\n",
        "        new_data_len = new_data.shape[0]\n",
        "        ids = (np.arange(new_data_len) + self.db_offset)\n",
        "        self.db[ids] = new_data\n",
        "        self.db_offset += new_data_len\n",
        "        # Write to file\n",
        "        self.db.flush()\n",
        "\n",
        "\n",
        "    def search_and_retrieve(self, query_vecs, topk):\n",
        "        query_vecs = query_vecs\n",
        "        distances, indices = self.index.search(query_vecs, topk)\n",
        "        kvs = self.db[indices]\n",
        "        return kvs\n",
        "\n",
        "    def add(self, new_data):\n",
        "        # Input is b n 2 d, flatten to (b n) 2 d\n",
        "        new_data = new_data.flatten(0,1)\n",
        "        # Add to db\n",
        "        self.add_to_db(new_data)\n",
        "        # Only keys are used in knn index\n",
        "        keys, vals = new_data.unbind(dim=-2)\n",
        "        # Add (b n) d tensors to index\n",
        "        keys = np.ascontiguousarray(keys.numpy())\n",
        "        # Add to index\n",
        "        self.index.add(keys)\n",
        "\n",
        "    def search(self, query_vecs, topk):\n",
        "        # can override topk\n",
        "        query_batch_size, query_seq_len = query_vecs.shape[0], query_vecs.shape[1]\n",
        "        # Input is b n d, flatten to (b n) d\n",
        "        query_vecs = query_vecs.flatten(0,1)\n",
        "        kvs = self.search_and_retrieve(np.ascontiguousarray(query_vecs.numpy()), topk)\n",
        "        # kvs are (b n) k 2 d, unflatten to b n k 2 d\n",
        "        kvs = torch.tensor(kvs)\n",
        "        kvs = torch.unflatten(kvs, 0, (query_batch_size, query_seq_len))\n",
        "        return kvs\n",
        "\n",
        "    def clear(self):\n",
        "        self.index.reset()\n",
        "        self.db[:] = 0\n",
        "        self.db_offset = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jS267DoAmgeB"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "dim = 10\n",
        "segments = 10\n",
        "seq_len = 512\n",
        "max_memories = batch_size * seq_len * segments\n",
        "\n",
        "knn = KNN(dim=dim, max_memories=max_memories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VH-RjhQPmggB"
      },
      "outputs": [],
      "source": [
        "kv = torch.randn(batch_size, seq_len, 2, dim) # b t 2 (hd)\n",
        "query = torch.randn(batch_size, seq_len, dim) # b t (hd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_d7ygNStmgiM"
      },
      "outputs": [],
      "source": [
        "knn.add(kv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgKQv_zImgkN",
        "outputId": "c445d64c-6e4e-4e17-bfc3-7478ce53df9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8192"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "knn.index.ntotal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwlLn9UtmgmJ",
        "outputId": "bde80733-1973-40e0-e815-e46d9c2379f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "memmap([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "knn.db[8192]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nSjLCoTLmgoR"
      },
      "outputs": [],
      "source": [
        "retrieved_kvs = knn.search(query, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnl3KW3mgqo",
        "outputId": "6f5660da-6d8b-4a43-83ec-44309eac61d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 3, 2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "retrieved_kvs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdx7-bVSAet0"
      },
      "source": [
        "The provided code defines a Multi-Head Attention (MHAttention) mechanism and attempts to incorporate k-Nearest Neighbor (kNN) memory into the attention process. This setup aims to extend the traditional attention mechanism by allowing the model to search and retrieve past memory entries during the forward pass, improving performance in tasks that benefit from long-term context retention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xNGa2KirPun"
      },
      "source": [
        "### KNN Attention Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QXTLs26Aet1"
      },
      "source": [
        "### Breakdown of the Key Components:\n",
        "\n",
        "1. **Multi-Head Attention (MHAttention):**\n",
        "   - **Embedding Transformation:** The input embeddings (`x`) are transformed into queries, keys, and values through linear layers (`query_matrix`, `key_matrix`, `value_matrix`). Each of these is then reshaped into multiple heads for parallel computation.\n",
        "   - **Attention Mechanism:** The queries and keys are multiplied (`qk = q @ k`) to compute attention scores. These scores are then masked and passed through a softmax function to normalize the attention weights.\n",
        "   - **Weighted Sum:** The attention scores are multiplied with the values (`qkv = qk @ v`), which gives the contextually weighted values for the attention mechanism.\n",
        "\n",
        "2. **Incorporating kNN Memory:**\n",
        "   - **Memory Representation:** The idea is to maintain a set of key-value pairs (from past computations) that can be accessed based on the current query (`q`). In the forward pass, a kNN search would retrieve the top `k` nearest neighbors of the query, providing additional context.\n",
        "   - **Reshaping for kNN Search:** The queries and memory keys/values are appropriately reshaped and permuted to allow for efficient computation of the attention mechanism with memory.\n",
        "   - **Memory Query:** The retrieved memory (from kNN) is integrated into the attention calculation, essentially combining both attention weights (`qkv`) and memory-weighted results (`mem_qkv`). This enhances the model's ability to remember and leverage previous context dynamically.\n",
        "\n",
        "3. **Further Details:**\n",
        "   - **Masking and Softmax:** After computing the initial attention scores (`qk`), a triangular mask is applied to prevent attention to future positions (common in autoregressive tasks). The softmax function then ensures the weights are normalized.\n",
        "   - **Attention Gates:** A parameterized gate (`gate`) is used to combine the standard attention and memory-based attention results, allowing the model to balance between the two.\n",
        "  \n",
        "### Memory Mechanism:\n",
        "The memory mechanism allows the model to \"remember\" useful past information and use it during the current attention computation. This is typically useful in situations where long-term dependencies are important (e.g., language models with long contexts). The memory is queried by `mem_qk = einsum(queries, mem_k, 'b h t d, b h t k d -> b h t k')`, which computes the attention between the current query and the stored memory keys.\n",
        "\n",
        "### Key Challenges and TODOs:\n",
        "- **Relative Position Encoding:** The code mentions an intended feature to integrate relative position encoding into the attention scores (`qk = relative_position_values + qk`), which would help in capturing the position of tokens relative to each other in the sequence.\n",
        "- **KNN Integration:** The actual kNN memory retrieval (`mem_qkv`) is marked as a TODO, implying that the memory query and retrieval from a kNN model should be implemented and connected to the existing attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0VmWJ5G5pOh9"
      },
      "outputs": [],
      "source": [
        "class MHAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        # Separate  into heads for multi-head attention\n",
        "        k = keys.reshape(batch_size, sequence_length, self.heads, head_dimension)\n",
        "        q = queries.reshape(batch_size, sequence_length, self.heads, head_dimension)\n",
        "        v = values.reshape(batch_size, sequence_length, self.heads, head_dimension)\n",
        "\n",
        "        # Swap head and sequence length dimensions\n",
        "        q = q.transpose(1,2)\n",
        "        k = k.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "        # Rearrange keys to prepare for matrix multiplication q@k\n",
        "        k = k.transpose(2,3)\n",
        "\n",
        "        # QK\n",
        "        qk = q@k\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # qk = relative_position_values + qk\n",
        "        ############\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        qkv = qk@v\n",
        "        qkv = qkv.transpose(1,2)\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.heads * head_dimension)\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # KNN Memory\n",
        "        ############\n",
        "\n",
        "        out = self.output_matrix(qkv)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSSMdO49xKOx"
      },
      "outputs": [],
      "source": [
        "# make sure q is (b t (hd)) for searching in knn (reshape and transpose)\n",
        "# knn returns (b t k 2 (hd))\n",
        "# split to key and value each size (b n k (hd)) (unbind)\n",
        "# convert k and v to (b t k h d) (reshape)\n",
        "# change q to (b h t d) (transpose)\n",
        "# change k to (b h t d k) (multiple transpose)\n",
        "# change v to (b h t k d) (multiple transpose)\n",
        "# get qk of  (b h t d) @ (b h t d k) -> (b h t k)\n",
        "# get qkv of (b h t k) @ (b h t k d) -> (b h t d)\n",
        "# .....\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruqKOV82xKQh",
        "outputId": "6f36cf64-d8c6-4f5f-f64d-8516a03b9c79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "number_heads = 8\n",
        "head_dimension = 10\n",
        "q = torch.randn(batch_size, seq_len, number_heads * head_dimension)\n",
        "k = torch.randn(batch_size, seq_len, number_heads * head_dimension)\n",
        "k.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_hkfhBXxKSB",
        "outputId": "56ba2002-3dfd-4c70-c2c9-d7b44baa6112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries: torch.Size([16, 8, 512, 10])\n",
            "keys: torch.Size([16, 8, 10, 512])\n",
            "qk: torch.Size([16, 8, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "# Manually\n",
        "\n",
        "# Separate queries matrix into heads for multi-head attention\n",
        "q = q.reshape(batch_size, seq_len, number_heads, head_dimension)\n",
        "# Rearrange indices to prepare for matrix multiplication q@k\n",
        "q = q.transpose(1,2)\n",
        "# Separate keys matrix into heads for multi-head attention\n",
        "k = k.reshape(batch_size, seq_len, number_heads, head_dimension)\n",
        "# Rearrange indices to prepare for matrix multiplication q@k\n",
        "k = k.permute(0,2,3,1)\n",
        "\n",
        "manual_qk = q@k\n",
        "\n",
        "print (\"queries:\", q.shape)\n",
        "print (\"keys:\", k.shape)\n",
        "print (\"qk:\", manual_qk.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KrE-bQcPpc3"
      },
      "source": [
        "### Einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzvSptOMxKT3",
        "outputId": "75c74056-eda5-4cc2-cd26-0e6bf7c2f97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "from einops import rearrange, repeat, pack, unpack, einsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhWZp_C_xKV4",
        "outputId": "04e9a0d9-0791-4daa-c698-cb625a834d38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "q = torch.randn(batch_size, seq_len, number_heads * head_dimension)\n",
        "k = torch.randn(batch_size, seq_len, number_heads * head_dimension)\n",
        "k.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGMEvXrIxKXs",
        "outputId": "2fdc5af7-8060-4798-d09a-fe195812290e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries: torch.Size([16, 8, 512, 10])\n",
            "keys: torch.Size([16, 8, 512, 10])\n",
            "qk: torch.Size([16, 8, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "# With einsum\n",
        "q =  rearrange(q, 'b t (h d) -> b h t d', h = number_heads)\n",
        "k =  rearrange(k, 'b t (h d) -> b h t d', h = number_heads)\n",
        "qk = einsum(q, k, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "print (\"queries:\", q.shape)\n",
        "print (\"keys:\", k.shape)\n",
        "print (\"qk:\", qk.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Techniques Used:\n",
        "- **`einsum`:** Efficiently computes tensor contractions (like matrix multiplications) and is used here to compute the attention scores between queries and keys, as well as the weighted sums.\n",
        "- **`rearrange` from Einops:** This function reshapes tensors to facilitate operations like multi-head attention where dimensions need to be adjusted for head-based parallelism."
      ],
      "metadata": {
        "id": "vkyWKNyxLD_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luzxDCp5xKfq"
      },
      "outputs": [],
      "source": [
        "# (3,4) (3,4) -> x@y.T -> (3,3)\n",
        "# multiply along b (4) dimension\n",
        "einsum(x, y, 'a b, c b -> a c')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5Ryfk-SxKhx"
      },
      "outputs": [],
      "source": [
        "# (3,4) (3,4) -> x.T@y -> (4,4)\n",
        "# multiply along a (3) dimension\n",
        "einsum(x, y, 'a b, a d -> d b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8kWr9GCxKjo"
      },
      "outputs": [],
      "source": [
        "# The repeated letter in different inputs tells einsum to multiply along that dimension\n",
        "# The differing letters in different inputs tells einsum to give those dimensions as the shape of the output\n",
        "# Leaving out letters means that axis will be summed\n",
        "# The output dimensions can be in any order you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X604ZaVxKl1"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(24, 10, 15)\n",
        "rearrange(x, '(a b) c (d e) -> (e c) a b d', a=6, e=5).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9-VrrYAxKn9"
      },
      "outputs": [],
      "source": [
        "\n",
        "q =  rearrange(q, 'b t (h d) -> b h t d', h = number_heads)\n",
        "k =  rearrange(k, 'b t (h d) -> b h t d', h = number_heads)\n",
        "qk = einsum(q, k, 'b h i d, b h j d -> b h i j')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "lSpcApjLpO3m"
      },
      "outputs": [],
      "source": [
        "class KNNAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # qk = relative_position_values + qk\n",
        "        ############\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "        qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # KNN Memory\n",
        "        ############\n",
        "\n",
        "        out = self.output_matrix(qkv)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "PjwWkXq9pO5i"
      },
      "outputs": [],
      "source": [
        "queries = torch.randn(batch_size, number_heads, seq_len, head_dimension)\n",
        "mem_kv = torch.randn(batch_size, seq_len, 3, 2, number_heads*head_dimension)\n",
        "scale = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpBe75qqpO7d",
        "outputId": "61803305-4dae-4e25-c21a-d7c058e2a389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "queries = rearrange(queries, 'b h t d -> b t (h d)')\n",
        "queries.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LP9p1FhpO9e",
        "outputId": "499da367-9bb5-4c4f-9b5e-fb7cc0936512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 8, 512, 3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# mem_kv = knn.search(queries, topk)\n",
        "mem_k, mem_v = mem_kv.unbind(dim = -2)\n",
        "mem_k = rearrange(mem_k, 'b t k (h d) -> b h t k d', h=number_heads)\n",
        "mem_v = rearrange(mem_v, 'b t k (h d) -> b h t k d', h=number_heads)\n",
        "mem_v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGdg7vLJmgsl",
        "outputId": "728597cd-e944-4a43-ad84-3a1f98b6b284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 8, 512, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "queries = rearrange(queries, 'b t (h d) -> b h t d', h=number_heads)\n",
        "mem_qk = einsum(queries, mem_k, 'b h t d, b h t k d -> b h t k') # d dimension\n",
        "mem_qk.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "P632FwZZ7036"
      },
      "outputs": [],
      "source": [
        "mem_qk = mem_qk * scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgdiZLfX706H",
        "outputId": "898934d7-b9b0-4074-d8dd-11a1db4247e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 8, 512, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "mem_qk = F.softmax(mem_qk, dim=-1)\n",
        "mem_qkv = einsum(mem_qk, mem_v, 'b h t k, b h t k d -> b h t d') # k dimension\n",
        "mem_qkv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqEZYNdh708E"
      },
      "outputs": [],
      "source": [
        "# gate between 0 and 1\n",
        "gate = nn.Parameter(torch.randn(number_heads, 1, 1))\n",
        "combined_qkv = (mem_qkv * gate) + (qkv * (1 - gate))\n",
        "out = output_matrix(combined_qkv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnYpGXSFOGhr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On_zu7zPAet8"
      },
      "source": [
        "The `KNNAttention` class in your code incorporates a **k-Nearest Neighbor (kNN) memory** component into the traditional transformer-based **multi-head attention** mechanism. This design adds a dynamic memory retrieval step to the attention mechanism, allowing the model to access stored past context when processing the current input.\n",
        "\n",
        "Here’s an overview of the design and operations involved:\n",
        "\n",
        "### Key Components:\n",
        "1. **Local Attention:**\n",
        "   - The input query (`q`), key (`k`), and value (`v`) matrices are transformed using linear layers (`query_matrix`, `key_matrix`, `value_matrix`), then reshaped into multi-head attention format using `rearrange`.\n",
        "   - The attention scores (`qk`) are computed using a matrix multiplication between queries and keys, followed by softmax normalization and a weighted sum of values (`qkv`).\n",
        "\n",
        "2. **KNN Attention:**\n",
        "   - After computing the local attention (`qkv`), kNN is used to retrieve `topk_retrieved_memories` for each query from a memory bank (`mem_kv`).\n",
        "   - The kNN search step involves converting the queries into a search-friendly format and retrieving the top-k nearest memory keys and values.\n",
        "   - These memory keys and values are used to compute attention scores (`mem_qk`), similar to the local attention calculation but with memory-specific keys and values.\n",
        "\n",
        "3. **Combining Local and Memory-based Attention:**\n",
        "   - A **gate bias** parameter (`self.gate_bias`) is used to combine the local attention and memory-based attention in a learnable way.\n",
        "   - The final output is a weighted combination of the local attention (`qkv`) and memory-based attention (`mem_qkv`), passed through the output layer (`output_matrix`).\n",
        "\n",
        "### Operations in KNN Memory:\n",
        "- **Add:** New memory entries can be added when performing a kNN search or memory update.\n",
        "- **Store:** Memory is stored in a form that allows fast search (e.g., vectors stored in an indexed form).\n",
        "- **Search:** A kNN search finds the most relevant stored memories (using a search mechanism like approximate nearest neighbors).\n",
        "- **Remove:** In certain memory systems, removing outdated or irrelevant memories is necessary.\n",
        "- **Reconstruct:** If using lossy memory (e.g., compression), the original state could be reconstructed from the memory.\n",
        "\n",
        "### Considerations for Index/Chip Paradigm:\n",
        "1. **Required Operations:**\n",
        "   - **Add** and **Search** operations are crucial. The kNN mechanism allows for efficient retrieval of memories during the forward pass. Depending on the task, **Remove** and **Reconstruct** operations could be required to manage memory efficiently.\n",
        "\n",
        "2. **Frequency of Operations:**\n",
        "   - **Search** is likely the most frequent operation, as it's called for every forward pass. The other operations (add, remove, reconstruct) are less frequent and typically handled at model updates or during memory management.\n",
        "\n",
        "3. **Accuracy vs. Speed vs. Memory Footprint:**\n",
        "   - **Accuracy:** The accuracy of the attention mechanism is enhanced by incorporating relevant past memories, especially for tasks requiring long-term dependencies.\n",
        "   - **Speed:** The use of kNN can slow down the model, depending on the search method used. Approximate nearest neighbors (ANN) methods can help speed this up, but there's a trade-off between speed and accuracy.\n",
        "   - **Memory Footprint:** Storing a large memory bank increases memory requirements. The number of vectors stored (i.e., memory size) and the number of neighbors (`topk_retrieved_memories`) directly affect memory usage.\n",
        "\n",
        "4. **Size of Index/Query:**\n",
        "   - The **index size** (number of vectors stored) is dependent on the model’s memory capacity. This could range from hundreds of vectors to millions, depending on the scale.\n",
        "   - The **query size** is determined by the batch size and sequence length, with each query corresponding to a query vector that interacts with the memory.\n",
        "\n",
        "5. **GPU vs. CPU:**\n",
        "   - **GPU** is preferred for handling large-scale kNN memory retrieval and attention computation, especially for parallelized tasks.\n",
        "\n",
        "6. **Retraining the Index:**\n",
        "   - If the memory is dynamic (e.g., new data is continually added), **retraining the index** may be necessary to keep it up to date. This is especially true if the memory involves fixed vectors (e.g., word embeddings or historical states) that may need to be adjusted as new data arrives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPxMHTKu4FSi"
      },
      "outputs": [],
      "source": [
        "class KNNAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 32,\n",
        "        ######\n",
        "        topk_retrieved_memories = 3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "        #######\n",
        "        self.gate_bias = nn.Parameter(torch.randn(self.heads, 1, 1))\n",
        "        self.topk_retrieved_memories = topk_retrieved_memories\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "        #######\n",
        "        knn,\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        ### LOCAL ATTENTION\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # qk = relative_position_values + qk\n",
        "        ############\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "        qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "\n",
        "        ### KNN ATTENTION\n",
        "\n",
        "        # Convert queries to search form\n",
        "        queries = rearrange(queries, 'b h t d -> b t (h d)')\n",
        "        mem_kv = knn.search(queries, topk = self.topk_retrieved_memories) # returns b t k 2 d\n",
        "        mem_k, mem_v = mem_kv.unbind(dim = -2)\n",
        "        mem_k = rearrange(mem_k, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "        mem_v = rearrange(mem_v, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "\n",
        "        # Convert queries to attention form\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        mem_qk = einsum('b h t d, b h t k d -> b h t k', queries, mem_k)\n",
        "        mem_qk = mem_qk * self.scale\n",
        "\n",
        "        mem_qk = F.softmax(mem_qk, dim=-1)\n",
        "        mem_qk = self.dropout(mem_qk)\n",
        "        mem_qkv = einsum('b h t k, b h t k d -> b h t d', mem_qk, mem_v)\n",
        "\n",
        "        # Combined attentions\n",
        "\n",
        "        combined_qkv = mem_qkv * self.gate_bias + qkv * (1 - self.gate_bias)\n",
        "        combined_qkv = rearrange(combined_qkv, 'b h t d -> b t (h d)')\n",
        "        out = self.output_matrix(combined_qkv)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMsGf0CbAet_"
      },
      "source": [
        "### Key Concepts:\n",
        "- kNN (k-Nearest Neighbors): A method used to find the closest data points (neighbors) to a given query point based on some distance metric (e.g., Euclidean distance). In this code, faiss is used to perform this search efficiently on high-dimensional data.\n",
        "- Memory Management: Using np.memmap allows the model to handle large amounts of memory (e.g., past key-value pairs) without loading everything into RAM at once.\n",
        "- External Memory: This code augments the transformer model with an external memory where previous key-value pairs are stored. The transformer can then query this memory during training to retrieve relevant information, improving its performance on long-context tasks.\n",
        "\n",
        "### Why is this important?\n",
        "Adding kNN memory to transformers allows the model to:\n",
        "- Remember past information and use it for current tasks, which is particularly useful for tasks with long sequences or documents.\n",
        "- Improve performance on tasks like language modeling, translation, and other sequential tasks where earlier context is important.\n",
        "\n",
        "### Optimization Considerations:\n",
        "- **Approximate Nearest Neighbor (ANN):** To optimize search time, you can use ANN techniques like **HNSW (Hierarchical Navigable Small World)** graphs or **FAISS** (Facebook AI Similarity Search) for faster kNN searches.\n",
        "- **Memory Management:** Memory management techniques like **LRU (Least Recently Used)**, or more advanced methods such as **episodic memory**, can be employed to control which memories are kept or discarded based on relevance.\n",
        "\n",
        "\n",
        "### Summary:\n",
        "The code implements a **knn-based attention mechanism** within the context of transformers. This approach attempts to blend traditional multi-head attention with a kNN-based external memory, allowing the transformer to access long-term context more effectively. This hybrid architecture is particularly useful in tasks such as **memory-augmented networks**, **neural architectures for continual learning**, or **long-range dependency modeling**, where remembering past states or contexts is crucial."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qd3Tj5X8NJ3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}