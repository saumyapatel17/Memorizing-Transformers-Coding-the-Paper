# Memorizing-Transformers-Coding-the-Paper
Memorizing Transformers integrates K-Nearest Neighbors (KNN) memory retrieval into transformer models, enabling real-time knowledge acquisition without retraining. By enhancing attention with KNN and relative position encoding, it improves long-range sequence tasks, making it ideal for complex reasoning over large contexts.
